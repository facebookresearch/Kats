# Copyright (c) Facebook, Inc. and its affiliates.
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

# pyre-unsafe

"""
This module contains code to implement the global model algorithm as a Detector Model.
"""

import logging
from enum import Enum

import numpy as np
import pandas as pd
from kats.consts import TimeSeriesData
from kats.detectors.detector import DetectorModel
from kats.detectors.detector_consts import (
    AnomalyResponse,
    ConfidenceBand,
)
from kats.models.globalmodel.serialize import (
    load_global_model_from_json,
    global_model_to_json,
)
from kats.models.globalmodel.utils import fill_missing_value_na


def _convert_ts_to_df(ts: TimeSeriesData) -> pd.DataFrame:
    """Convert a TimeSeriesData object to a `pd.DataFrame` object.
    We do not directly use ts.to_dateframe() method to have control over the names of dataframe columns.
    """

    df = pd.DataFrame({"time": ts.time.values, "value": ts.value.values})
    return df


def deviation_from_confidence_band(
    predict_df: pd.DataFrame, ci_lower: str, ci_upper: str
) -> pd.Series:
    """Function for percentage magnitude score.

    The definition of the scoring function is
        score = (actual - ci_upper)/abs(ci_upper) if actual>ci_upper, or
        score = (actual - ci_lower)/abs(ci_lower) if actual<ci_lower.

    Args:
        predict_df: A `pd.DataFrame` object representing the dataframe containing the values of true value and confidence intervals.
        ci_lower: A string representing the name of the lower-bound of the confidence interval column.
        ci_upper: A string representing the name of the upper-bound of the confidence interval column.

    Returns:
        A  `pd.Series` object representing the perentage magnitude score.
    """
    over_upper = (predict_df["value"] - predict_df[ci_upper]) / np.abs(
        predict_df[ci_upper]
    )
    over_upper[over_upper < 0.0] = 0.0

    over_lower = (predict_df["value"] - predict_df[ci_lower]) / np.abs(
        predict_df[ci_lower]
    )
    over_lower[over_lower > 0.0] = 0.0

    return (over_upper + over_lower) * 100


class GMScoreFunction(Enum):
    """A class for scoring functions of GMDetector."""

    deviation_from_confidence_band = "deviation_from_confidence_band"


SCORE_FUNC_DICT = {"deviation_from_confidence_band": deviation_from_confidence_band}


class GMDetectorModel(DetectorModel):
    """Global model based anomaly detection model.

    A detection model based on global model, which detects the anomalies by comparing actual observed values to
    the forecasts generated by the global model.

    Attributes:
        serialized_model: A byte string representing the serialized GM.
        score_func: A GMScoreFunction object representing the scoring function.
        scoring_confidence_interval: A float representing the confidence interval used by scoring function.
            Default is 0.9 which represents the 90% confidence interval.
        remove_outliers: A boolean representing whether should remove_outliers or not.
        outlier_confidence_interval: A float representing the confidence interval used by removing outliers in historical data.
            Default is 0.98 which represents the 98% confidence interval.
        outlier_removal_window: An integer representing the length of the historical data whose outliers to be removed.
            Default is 7, which means the detector will remove the outliers within the last 7 data points of the historical data if remove_outliers is True.
        max_abnormal_continuation: An integer representing the max length of outlier continuation. Default is 3, which means when we observe the last three
            data points of historical data are all outliers, we take them as new trend of data and keep them (rather than removing them).
    """

    def __init__(
        self,
        serialized_model: bytes,
        score_func: GMScoreFunction = GMScoreFunction.deviation_from_confidence_band,
        scoring_confidence_interval: float = 0.9,
        remove_outliers=False,
        outlier_confidence_interval: float = 0.98,
        outlier_removal_window: int = 7,
        max_abnormal_continuation: int = 3,
    ) -> None:

        self.model = load_global_model_from_json(serialized_model.decode())

        available_quantiles = set(self.model.params.quantile)

        scoring_lower, scoring_upper = round(
            (1 - scoring_confidence_interval) / 2.0, 2
        ), round(0.5 + scoring_confidence_interval / 2.0, 2)
        # validate scoring_confidence_interval
        if (
            scoring_lower not in available_quantiles
            or scoring_upper not in available_quantiles
        ):
            msg = f"scoring_confidence_interval is not valid since input GM only provides quantiles {available_quantiles}."
            logging.error(msg)
            raise ValueError(msg)

        outlier_lower, outlier_upper = round(
            (1 - outlier_confidence_interval) / 2.0, 2
        ), round(0.5 + outlier_confidence_interval / 2.0, 2)
        # validate scoring_confidence_interval
        if (
            outlier_lower not in available_quantiles
            or outlier_upper not in available_quantiles
        ):
            msg = f"outlier_confidence_interval is not valid since input GM only provides quantiles {available_quantiles}."
            logging.error(msg)
            raise ValueError(msg)

        self.score_func = score_func
        self.remove_outliers = remove_outliers
        self.outlier_removal_window = outlier_removal_window
        self.max_abnormal_continuation = max_abnormal_continuation

        self.scoring_lower = f"fcst_quantile_{scoring_lower}"
        self.scoring_upper = f"fcst_quantile_{scoring_upper}"

        self.outlier_lower = f"fcst_quantile_{outlier_lower}"
        self.outlier_upper = f"fcst_quantile_{outlier_upper}"

    def _remove_outliers(self, historical_data: TimeSeriesData) -> TimeSeriesData:

        if len(historical_data) < (
            self.model.params.seasonality + self.outlier_removal_window
        ):
            msg = f"historical data is too short! Minimum length should be {self.outlier_removal_window+self.model.params.seasonality}."
            logging.error(msg)
            raise ValueError(msg)

        # first generate forecasts for the outlier remove interval
        hist_fcst = self.model.predict(
            historical_data[: (-self.outlier_removal_window)],
            steps=self.outlier_removal_window,
        )[0]

        # filter out the outliers
        raw_value = historical_data.value.values[(-self.outlier_removal_window) :]
        outlier = (raw_value < hist_fcst[self.outlier_lower]) | (
            raw_value > hist_fcst[self.outlier_upper]
        )

        # remove consecutive outliers
        if np.all(outlier[-self.max_abnormal_continuation :]):
            outlier[-self.max_abnormal_continuation :] = False

        historical_data.value.values[(-self.outlier_removal_window) :][outlier] = np.nan

        return historical_data

    def serialize(self) -> bytes:
        """Serialize the global model."""

        return (global_model_to_json(self.model)).encode()

    # pyre-fixme
    def fit(self, data: TimeSeriesData, historical_data: TimeSeriesData) -> None:
        """
        Global model training offline, so this is a no-op.
        """
        pass

    # pyre-fixme
    def fit_predict(
        self, data: TimeSeriesData, historical_data: TimeSeriesData
    ) -> AnomalyResponse:
        """The same as function predict, which returns an AnomalyResponse object representing the anomaly information.

        Args:
            data: A `kats.consts.TimeSeriesData` object representing the data on which the detector runs.
            historical_data: A `kats.consts.TimeSeriesData` object representing the historical data.

        Returns:
            An AnomalyResponse object.
        """
        return self.predict(data, historical_data)

    # pyre-fixme
    def predict(
        self, data: TimeSeriesData, historical_data: TimeSeriesData
    ) -> AnomalyResponse:
        """Predicts tha anomaly scores for future data.

        Args:
            data: A `kats.consts.TimeSeriesData` object representing the data on which the detector runs.
            historical_data: A `kats.consts.TimeSeriesData` object representing the historical data.

        Returns:
            An AnomalyResponse object.
        """

        historical_data = fill_missing_value_na(
            historical_data, self.model.params.seasonality, self.model.params.freq
        )

        if len(historical_data) < self.model.params.seasonality:
            msg = f"historical data is too short! Minimum length should be {self.model.params.seasonality+1}."
            logging.error(msg)
            raise ValueError(msg)

        if self.remove_outliers:
            historical_data = self._remove_outliers(historical_data)

        if historical_data.value.std() == 0:
            # get the first not NaN value
            val = historical_data.value.loc[historical_data.value.first_valid_index()]
            pred_df = pd.DataFrame(
                {
                    "time": data.time.values,
                    "value": data.value.values,
                    "fcst_quantile_0.5": [val] * len(data),
                    self.scoring_lower: [val] * len(data),
                    self.scoring_upper: [val] * len(data),
                }
            )
        else:
            # Generate forecasts using GM
            data_df = _convert_ts_to_df(data)
            steps = int(
                (data.time.iloc[-1] - historical_data.time.iloc[-1])
                / self.model.params.freq
            )
            pred_df = data_df.merge(
                self.model.predict(historical_data, steps=steps)[0], on="time"
            )

        response = AnomalyResponse(
            scores=TimeSeriesData(
                time=pred_df.time,
                value=SCORE_FUNC_DICT[self.score_func.value](
                    pred_df, self.scoring_lower, self.scoring_upper
                ),
            ),
            confidence_band=ConfidenceBand(
                upper=TimeSeriesData(
                    time=pred_df.time, value=pred_df[self.scoring_upper]
                ),
                lower=TimeSeriesData(
                    time=pred_df.time, value=pred_df[self.scoring_lower]
                ),
            ),
            predicted_ts=TimeSeriesData(time=pred_df.time, value=pred_df.value),
            anomaly_magnitude_ts=TimeSeriesData(
                time=data.time, value=pd.Series([0] * len(pred_df))
            ),
            stat_sig_ts=TimeSeriesData(
                time=data.time, value=pd.Series([0] * len(pred_df))
            ),
        )

        return response
