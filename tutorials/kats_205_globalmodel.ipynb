{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kats 205 Forecasting with Global Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will introduce how to use the global model in Kats.  The global model is a new and powerful forecasting method that combines exponential smoothing models with recurrent neural networks, resulting in higher accuracy than other approaches. The table of contents for Kats 205 is as follows:\n",
    "\n",
    "1. Overview of global model for forecasting  \n",
    "2. Building your own global model/global ensemble from scratch  \n",
    "    2.1 Introduction to `GMParam`  \n",
    "    2.2 Forecasting using a single global model with `GMModel`  \n",
    "    2.3 Forecasting using a global model ensemble with `GMEnsemble`  \n",
    "    2.4 Backtesting with `GMBacktester`  \n",
    "3. Using pretrained global model/global ensemble  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We provide two types of tutorial notebooks\n",
    "- **Kats 101**, basic data structure and functionalities in Kats \n",
    "- **Kats 20x**, advanced topics, including advanced forecasting techniques, advanced detection algorithms, `TsFeatures`, meta-learning, global model etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview of global model for forecasting\n",
    "\n",
    "Global model (GM) is a powerful forecasting model based on neural networks, which is first proposed by Slawek Smyl and is the winning model of the M4 Forecasting competition (2018) and the Computational Intelligence in Forecasting International Time Series Competition (2016) (reference of the original model: https://www.sciencedirect.com/science/article/pii/S0169207019301153). Unlike traditional forecasting model (e.g., ARIMA or Prophet), GM is trained with a large amount of time series and can be used for forecasting any new unseen time series of the same time granularity. Its award winning performance verifies that GM is of high accuracy. Moreover, GM is generic for batch processing (i.e., generating forecasts for several time series at the same time) and enjoys suprior efficiency. \n",
    "\n",
    "In Kats, we build upon the original model and provide two types of GMs: RNN-GM (for short-term forecasting) and S2S-GM (for mid-term/long-term forecasting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building your own global model/global ensemble from scratch\n",
    "\n",
    "The `GMModel` and `GMEnsemble` class allow you to build a single GM or an ensemble of several independent GMs (GME). The `GMParam` class encodes all the necessary configerations of a GM including NN structure, time series granularity and etc. In addition, we provide class `GMBacktester` for parameter tunning and backtesting. \n",
    "\n",
    "In this section, we will only display the functionality of each class (hence the models are not well-trained and may not provide good performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Introduction to `GMParam`\n",
    "\n",
    "A `GMParam` object carries all the necessary configerations of a GM (or a GME), and it performs basic parameter checking when initialized. Here we list several importand arguments for `GMParam`:\n",
    "\n",
    "* **freq**: String or pd.Timedelta; The time granularity of the model (and the time series.) For example, `freq='D'` indicates a daily model.\n",
    "* **model_type**: String; The name of neural network type. Should be either 'rnn' or 's2s'. Default is 'rnn'.\n",
    "* **input_window**: Integer; An integer representing length of input TS of each step and it should be greater than seasonality.\n",
    "* **fcst_window**: Integer; An integer representing the length of each forecast step. When `model_type='s2s'`, the loss function is computed over the sub time series of length `fcst_window*fcst_step_num`. Note that GM/GME can generate forecasts of any length regardless of `fcst_window`. \n",
    "* **seasonality**: Integer; An integer representing representing the seasonality period. When `seasonality=1`, the global model is non-seasonal. Default is 1.\n",
    "* **quantile**: List of floats; A list of floats representing the forecast quantile (the first element should be 0.5 representing the mean/median value). Default value is [0.5,0.05,0.95,0.99].\n",
    "* **nn_structure**: List of lists of integers; A list of lists of integers representing the neural network structure. If None, default value is [[1,3]].\n",
    "* **loss_function**: String; The name of loss function, can be 'pinball' or 'adjustedpinball'.\n",
    "* **gmfeature**: List of strings or string; A single or a list of feature names.\n",
    "\n",
    "For the definition of other parameters, please see our documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from kats.models.globalmodel.utils import GMParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMParam example  -- for daily model\n",
    "gmparam = GMParam(\n",
    "    input_window = 35, \n",
    "    fcst_window = 31,\n",
    "    seasonality = 7,\n",
    "    freq = 'D',\n",
    "    loss_function = 'adjustedpinball',\n",
    "    nn_structure = [[1,3]],\n",
    "    gmfeature = ['last_date'],\n",
    "    epoch_num = 1, \n",
    "    epoch_size = 2, # use a small num just for demonstration\n",
    "    gmname = \"daily_default\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Forecasting using a single global model with GMModel\n",
    "\n",
    "After initiating a `GMParam` object, you are ready to build and train a single global model. To initiate a `GMModel` object, one only needs to input the `GMParam` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.globalmodel.model import GMModel, load_gmmodel_from_file\n",
    "from kats.models.globalmodel.serialize import global_model_to_json, load_global_model_from_json\n",
    "from kats.consts import TimeSeriesData\n",
    "\n",
    "# build `GMModel` object\n",
    "\n",
    "gm = GMModel(gmparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a `GMModel` object, we need a list or a dictionary of time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss_monitor': [0.1050752], 'valid_loss_monitor': [{'epoch': 0}], 'valid_fcst_monitor': [], 'train_loss_val': [0.21015039831399918]}\n"
     ]
    }
   ],
   "source": [
    "# helper function for simulating random time series.\n",
    "\n",
    "def get_ts(n, start_time, freq='D', has_nans=True):\n",
    "    \"\"\"Function for simulating time series.\n",
    "    \n",
    "    Args: \n",
    "        n: An integer representing the length of time series.\n",
    "        start_time: A string representing the starting timestamp of time series.\n",
    "        freq: A string representing the time granularity of time series.\n",
    "        has_nans: A boolearn representing whether or not time series has NaNs.\n",
    "    \n",
    "    Returns:\n",
    "        A simulated time series.\n",
    "    \"\"\"\n",
    "    t = pd.Series(pd.date_range(start_time, freq=freq, periods=n))\n",
    "    val = np.random.randn(n)\n",
    "    if has_nans:\n",
    "        idx = np.random.choice(range(n), int(n*0.2), replace=False)\n",
    "        val[idx]=np.nan\n",
    "    val = pd.Series(val)\n",
    "    return TimeSeriesData(time=t, value=val)\n",
    "\n",
    "train_TSs = {i: get_ts(n*5, '2020-05-06') for i, n in enumerate(list(range(20, 40)))}\n",
    "test_TSs = {i: get_ts(n*2, '2020-05-06') for i, n in enumerate(list(range(40, 42)))}\n",
    "\n",
    "# train the model\n",
    "training_info = gm.train(train_TSs)\n",
    "\n",
    "#training_info saves the information of training process\n",
    "print(training_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the trained model to generate forecasts. The input can be a `TimeSeriesData` object or a list/dictionary of TimeSeriesData objects. The returned value is a dictionary of `pd.DataFrame` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe of forecasts is {0:    fcst_quantile_0.5  fcst_quantile_0.05  fcst_quantile_0.95  \\\n",
      "0            1.07464            0.107831            1.566863   \n",
      "1            1.71647            0.569356            1.982417   \n",
      "2           -0.47167           -0.719296           -0.026999   \n",
      "\n",
      "   fcst_quantile_0.99       time  \n",
      "0            1.359847 2020-06-05  \n",
      "1            1.931908 2020-06-06  \n",
      "2           -0.571826 2020-06-07  }.\n",
      "========================================================================================================================\n",
      "The dictionary of forecasts is {0:    fcst_quantile_0.5  fcst_quantile_0.05  fcst_quantile_0.95  \\\n",
      "0          -0.835291           -1.531433           -0.507440   \n",
      "1          -0.916999           -1.478367           -0.646848   \n",
      "2          -1.067785           -1.373956           -0.773177   \n",
      "\n",
      "   fcst_quantile_0.99       time  \n",
      "0           -0.677720 2020-07-25  \n",
      "1           -0.658723 2020-07-26  \n",
      "2           -1.174261 2020-07-27  , 1:    fcst_quantile_0.5  fcst_quantile_0.05  fcst_quantile_0.95  \\\n",
      "0          -1.011401           -1.823488           -0.651751   \n",
      "1          -0.658375           -1.403097           -0.360127   \n",
      "2          -1.386420           -1.696839           -1.006883   \n",
      "\n",
      "   fcst_quantile_0.99       time  \n",
      "0           -0.815833 2020-07-27  \n",
      "1           -0.342349 2020-07-28  \n",
      "2           -1.486901 2020-07-29  }.\n"
     ]
    }
   ],
   "source": [
    "test_ts = get_ts(30, '2020-05-06')\n",
    "fcst = gm.predict(test_ts, steps = 3)\n",
    "print(f\"The dataframe of forecasts is {fcst}.\")\n",
    "print(\"==\"*60)\n",
    "\n",
    "# generate the forecasts of a batch of time series.\n",
    "fcsts = gm.predict(test_TSs, steps = 3)\n",
    "print(f\"The dictionary of forecasts is {fcsts}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now display how to save and reload the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "gm.save_model(\"gm_example_1.p\")\n",
    "\n",
    "# load model\n",
    "gm2 = load_gmmodel_from_file(\"gm_example_1.p\")\n",
    "\n",
    "# remove the saved model\n",
    "os.remove(\"gm_example_1.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide methods for encoding GM into a json string, and loading a model from a json string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode model into json string\n",
    "gm_str = global_model_to_json(gm)\n",
    "\n",
    "# load model from json string\n",
    "gm3 = load_global_model_from_json(gm_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Forecasting using a single global model with GMEnsemble\n",
    "\n",
    "You can also easily build one ensemble of several individual GMs with `GMEnsemble` class. In addition to a `GMParam` object, one also needs to specify how training data set should be splitted and how many independent `GMModel` objects. \n",
    "\n",
    "Here is the list of attributs:\n",
    "* **gmparam**: A GMParam object; This is used for initiating each global model.\n",
    "* **ensemble_type**: String; A string representing how forecasts are combined. Can be 'median' or 'mean'. Default is 'median'.\n",
    "* **splits**: Integer; An positive integer representing the number of sub-datasets to be built. Default is 3.\n",
    "* **overlap**: Boolean; A boolean representing whether or not sub-datasets overlap with each other or not. Default is True. For example, when `splits=3` and `overlap=True`, then each sub-dataset contains 2/3 of training data.\n",
    "* **replicate**: Integer; A positive integer representing the number of global models to be trained on each sub-datasets. Default is 1.\n",
    "* **multi**: Boolean; A boolean representing whether or not to use multi-processing for training and prediction. Default is False.\n",
    "\n",
    "Note that a GMEnsemble object will build `splits*replicate` independent `GMModel` objects, and the final forecasts are aggregated from the forecasts generated from each trained `GMModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.globalmodel.ensemble import GMEnsemble, load_gmensemble_from_file\n",
    "\n",
    "# Initiate \n",
    "gme = GMEnsemble(gmparam, splits=3, overlap=True, replicate=1, multi=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the `GMEnsemble` object. Note that one has the choice of setting aside a test set from the training data to measure the performance of each `GMModel` object throughout the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:206] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:206] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:206] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "gme.train(train_TSs, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_loss_monitor': [0.09529682],\n",
       "  'valid_loss_monitor': [{'epoch': 0}],\n",
       "  'valid_fcst_monitor': [],\n",
       "  'train_loss_val': [0.29780256748199463],\n",
       "  'test_info': [      smape     sbias  exceed_0.05  exceed_0.95  exceed_0.99  step  idx  epoch\n",
       "   0  1.718492 -1.418439     0.096774     0.677419     0.677419     0    9      0\n",
       "   1  1.551402 -0.258064     0.354839     0.419355     0.516129     0   11      0]},\n",
       " {'train_loss_monitor': [0.093351685],\n",
       "  'valid_loss_monitor': [{'epoch': 0}],\n",
       "  'valid_fcst_monitor': [],\n",
       "  'train_loss_val': [0.19837233051657677],\n",
       "  'test_info': [      smape     sbias  exceed_0.05  exceed_0.95  exceed_0.99  step  idx  epoch\n",
       "   0  1.749226 -1.445085     0.064516     0.709677     0.709677     0    9      0\n",
       "   1  1.678446 -0.379500     0.387097     0.451613     0.516129     0   11      0]},\n",
       " {'train_loss_monitor': [0.104721874],\n",
       "  'valid_loss_monitor': [{'epoch': 0}],\n",
       "  'valid_fcst_monitor': [],\n",
       "  'train_loss_val': [0.340346097946167],\n",
       "  'test_info': [      smape     sbias  exceed_0.05  exceed_0.95  exceed_0.99  step  idx  epoch\n",
       "   0  1.651052 -1.512098     0.064516     0.741935     0.709677     0    9      0\n",
       "   1  1.631879 -0.198445     0.354839     0.483871     0.483871     0   11      0]}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the information of training process and the evaluation results on the set-aside test set are saved in attribute gm_info.\n",
    "gme.gm_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the `GMEnsemble` object, you now can use it to generate forecasts. Similar to the `GMModel` object, the input can be a `TimeSeriesData` object or a list/dictionary of TimeSeriesData objects and the returned value is a dictionary of `pd.DataFrame` objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated forecasts is of type <class 'dict'>, and it is {0:    fcst_quantile_0.5  fcst_quantile_0.05  fcst_quantile_0.95  \\\n",
      "0          -0.220554            0.013514            0.044756   \n",
      "1          -0.016261           -0.315333           -0.010909   \n",
      "2           0.446663            0.037812            0.246893   \n",
      "\n",
      "   fcst_quantile_0.99       time  \n",
      "0           -0.527834 2020-07-25  \n",
      "1           -0.426698 2020-07-26  \n",
      "2           -0.338622 2020-07-27  , 1:    fcst_quantile_0.5  fcst_quantile_0.05  fcst_quantile_0.95  \\\n",
      "0          -0.948326           -0.751360           -0.743056   \n",
      "1          -0.470674           -0.765599           -0.452450   \n",
      "2           0.806719            0.348096            0.613019   \n",
      "\n",
      "   fcst_quantile_0.99       time  \n",
      "0           -1.233405 2020-07-27  \n",
      "1           -0.858695 2020-07-28  \n",
      "2           -0.111488 2020-07-29  }.\n"
     ]
    }
   ],
   "source": [
    "# generate forecasts\n",
    "fcsts=gme.predict(test_TSs, steps = 3)\n",
    "print(f\"The generated forecasts is of type {type(fcsts)}, and it is {fcsts}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the `GMModel` object, you can also easily save/load and serilize the `GMEnsemble` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "gme.save_model(\"gme_example_1.p\")\n",
    "\n",
    "# load model\n",
    "gme2 = load_gmensemble_from_file(\"gme_example_1.p\")\n",
    "\n",
    "# remove the saved model\n",
    "os.remove(\"gme_example_1.p\")\n",
    "\n",
    "\n",
    "# encode model into json string\n",
    "gme.gm_info=None # Note that pd.DataFrame is not serilizable\n",
    "gme_str = global_model_to_json(gme)\n",
    "\n",
    "# load model from json string\n",
    "gme3 = load_global_model_from_json(gme_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Backtesting with `GMBacktester`\n",
    "\n",
    "A `GMBacktester` object helps evaluate the hyper-parameter setting (i.e., the `GMParam` object). Here is a list of some of the attributes:\n",
    "* **data**: A list or a dictionary of `kats.consts.TimeSeriesData` objects for training and validation.\n",
    "* **gmparam**: A `GMParam` object.\n",
    "* **backtest_timestamp**: A list of strings or `pandas.Timestamp` objects representing the backtest timestamps. A backtest timestamp is used to split the time series into the training and testing set.\n",
    "* **splits**: Integer; An positive integer representing the number of sub-datasets to be built. Default is 3.\n",
    "* **overlap**: Boolean; A boolean representing whether or not sub-datasets overlap with each other or not. Default is True. For example, when `splits=3` and `overlap=True`, then each sub-dataset contains 2/3 of training data.\n",
    "* **replicate**: Integer; A positive integer representing the number of global models to be trained on each sub-datasets. Default is 1.\n",
    "\n",
    "For the full list of attributes, please see our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.models.globalmodel.backtester import GMBackTester\n",
    "\n",
    "# initiate backtester\n",
    "gbm = GMBackTester(train_TSs, gmparam, backtest_timestamp = ['2020-08-10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one can run backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smape</th>\n",
       "      <th>sbias</th>\n",
       "      <th>exceed_0.05</th>\n",
       "      <th>exceed_0.95</th>\n",
       "      <th>exceed_0.99</th>\n",
       "      <th>model_num</th>\n",
       "      <th>step</th>\n",
       "      <th>idx</th>\n",
       "      <th>type</th>\n",
       "      <th>backtest_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.112656</td>\n",
       "      <td>-1.112656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.104074</td>\n",
       "      <td>-0.895926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.056552</td>\n",
       "      <td>-1.056552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.056552</td>\n",
       "      <td>-1.056552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.422550</td>\n",
       "      <td>0.068835</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.476043</td>\n",
       "      <td>0.218554</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.413662</td>\n",
       "      <td>0.106427</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.425900</td>\n",
       "      <td>0.148917</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.041351</td>\n",
       "      <td>0.590719</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.318261</td>\n",
       "      <td>0.242540</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.101489</td>\n",
       "      <td>-0.183721</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>single</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.167561</td>\n",
       "      <td>0.246902</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>2020-08-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       smape     sbias  exceed_0.05  exceed_0.95  exceed_0.99  model_num  \\\n",
       "0   1.112656 -1.112656     0.000000     0.032258     0.032258        0.0   \n",
       "1   1.104074 -0.895926     0.000000     0.064516     0.032258        1.0   \n",
       "2   1.056552 -1.056552     0.000000     0.064516     0.064516        2.0   \n",
       "3   1.056552 -1.056552     0.000000     0.064516     0.032258        NaN   \n",
       "4   1.422550  0.068835     0.483871     0.419355     0.225806        0.0   \n",
       "5   1.476043  0.218554     0.387097     0.258065     0.322581        1.0   \n",
       "6   1.413662  0.106427     0.548387     0.354839     0.419355        2.0   \n",
       "7   1.425900  0.148917     0.516129     0.387097     0.322581        NaN   \n",
       "8   1.041351  0.590719     0.064516     0.129032     0.258065        0.0   \n",
       "9   1.318261  0.242540     0.193548     0.096774     0.225806        1.0   \n",
       "10  1.101489 -0.183721     0.032258     0.290323     0.193548        2.0   \n",
       "11  1.167561  0.246902     0.064516     0.129032     0.193548        NaN   \n",
       "\n",
       "    step  idx      type backtest_ts  \n",
       "0      0  0.0    single  2020-08-10  \n",
       "1      0  0.0    single  2020-08-10  \n",
       "2      0  0.0    single  2020-08-10  \n",
       "3      0  NaN  ensemble  2020-08-10  \n",
       "4      0  9.0    single  2020-08-10  \n",
       "5      0  9.0    single  2020-08-10  \n",
       "6      0  9.0    single  2020-08-10  \n",
       "7      0  NaN  ensemble  2020-08-10  \n",
       "8      1  9.0    single  2020-08-10  \n",
       "9      1  9.0    single  2020-08-10  \n",
       "10     1  9.0    single  2020-08-10  \n",
       "11     1  NaN  ensemble  2020-08-10  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.run_backtest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using pretrained global model/global ensemble\n",
    "\n",
    "In Kats, we provide two pre-trained daily `GMEnsemble` objects (one is S2S-GME and and the other one is RNN-GME). Both of them are trained with M4 dataset. One can use them for forecasting exploration or benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kats.models.globalmodel.ensemble.GMEnsemble at 0x7f9978740e20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gme_rnn = load_gmensemble_from_file(\"../kats/models/globalmodel/pretrained_daily_rnn.p\")\n",
    "gme_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this loaded pre-trained model to generate forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:    fcst_quantile_0.5  fcst_quantile_0.01  fcst_quantile_0.05  \\\n",
       " 0          -0.409422           -0.738302           -0.612039   \n",
       " 1          -0.341009           -0.804592           -0.612023   \n",
       " 2          -0.012784           -0.591704           -0.360692   \n",
       " \n",
       "    fcst_quantile_0.95  fcst_quantile_0.99       time  \n",
       " 0           -0.231685           -0.111664 2020-07-25  \n",
       " 1           -0.089894            0.092455 2020-07-26  \n",
       " 2            0.317086            0.563282 2020-07-27  ,\n",
       " 1:    fcst_quantile_0.5  fcst_quantile_0.01  fcst_quantile_0.05  \\\n",
       " 0          -0.578904           -0.850013           -0.740762   \n",
       " 1          -0.414955           -0.771584           -0.641951   \n",
       " 2          -0.019759           -0.485320           -0.311198   \n",
       " \n",
       "    fcst_quantile_0.95  fcst_quantile_0.99       time  \n",
       " 0           -0.475661           -0.388489 2020-07-27  \n",
       " 1           -0.259640           -0.137088 2020-07-28  \n",
       " 2            0.232197            0.349838 2020-07-29  }"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcsts = gme_rnn.predict(test_TSs, steps = 3)\n",
    "fcsts"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b6e8fba36db23bc4d54e0302cd75fdd75c29d9edcbab68d6cfc74e7e4b30305"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
