{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kats 204 Forecasting with Meta Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Kats, we provide a meta-learning framework to recommmend the best forecasting model for a time series.  Our framework provides the best model with tuned hyperparameters from the following family of models:\n",
    "\n",
    "1. ARIMA\n",
    "2. SARIMA\n",
    "3. Holt-Winters\n",
    "4. Prophet\n",
    "5. Theta\n",
    "6. STLF\n",
    "\n",
    "Given an input time series, there are four steps to this process:\n",
    "1. **Calculate Metadata For Input Time Series:** The three components of the metadata are as follows:     \n",
    "    a. The `TsFeatures`      \n",
    "    b. The best hyperparameters and corresponding errors metrics for each of the six aforementioned model families   \n",
    "    c. The best model family for the input time series (based on the error metrics)      \n",
    "2. **Determine If Input Time Series is Predictable (Optional)** This optional step determines if the input time series can be easily forecast with a single model.  \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proposed a meta-learning framework for forecasting predictability, model selection and hyper-parameters tuning (HPT) through a supervised learning perspective, which provides accurate forecasts with low computational time and resources. \n",
    "\n",
    "It first classifies whether a time series is predictable or not (i.e. whether we can get a good forecasts without much human-engineering efforts). Then it uses classification algorithm to predict the best forecasting model using the extracted time series features. Given the selected forecasting model, a multi-tasks neural network model is used to predict the best hyper parameters. \n",
    "\n",
    "The meta-learning framework contains four steps:\n",
    "\n",
    "1. Meta-data collection:  tuning to obtain the best performed model for a given time series, and hyper-parameters for each model and data combination. \n",
    "\n",
    "2. Predict whether a time series is predicatable or not. This is an optional examination step, which aims to inform user whether the target time series can be easily fitted by a single model or additional human-engineering efforts are needed.\n",
    "\n",
    "3. Predict forecasting model for the target time series.\n",
    "\n",
    "4. Predict hyper-parameters for the target time series.\n",
    "\n",
    "Kats provides APIs for all these steps.\n",
    "\n",
    "\n",
    "The table of contents for Kats 204 is as follows:\n",
    "1. Meta-data collection\n",
    "2. Meta-learning Predictability (Optional)\n",
    "3. Meta-learn Model Selection\n",
    "4. Meta-learning Hyper-parameter Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Meta-data collection**\n",
    "\n",
    "This module extracts the meta-data of a time series, which includes:\n",
    "\n",
    "1. The hyper-parameters and the corresponding forecasting errors of 6 best candidate models after hyper-parameter tuning; \n",
    "\n",
    "2. 40 time series features; \n",
    "\n",
    "3. Search method for hyper-parameter tuning (e.g., random search, grid search or Bayesian Optimal Search);\n",
    "\n",
    "4. Error metrics used in evaluating hyper-parameters (MAE is defualt and MAPE is recommended.).\n",
    "\n",
    "Paremeters for GetMetaData() class:\n",
    "* **data**: TimeSeriesData\n",
    "* **all_models**: Dict\\[str, m.Model], a dictionary that includes all candidate models.\n",
    "* **all_params**: Dict\\[str, Params], a dictionary that includes all candidate parameter class corresponding to the candidate models.\n",
    "* **min_length**: Optional; int, the minimal length of time series. Time series data whose length is shorter than min_length will be excluded.\n",
    "* **scale**: bool, It indicates whether to rescale TS before computing the time series feature vector. If true, then the time series will be normalized by its max value.\n",
    "* **method**: SearchMethodEnum, Search method for hyper-parameters tuning.\n",
    "* **executor**: Any, A callable parallel executor. Tune individual model in candidate models parallel. The default executor is native implementation with Python's multiprocessing.\n",
    "* **error_method**: str, Type of error metric. Only support mape, smape, mae, mase, mse, rmse.\n",
    "* **num_trials**: optional, Number of trials in RandomSearch.\n",
    "* **num_arm**: optional, Number of arms in RandomSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Collect meta-data from a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Feature vector contains NAN, features are {'length': 144, 'mean': 0.45064085387638453, 'var': 0.03694123647244219, 'entropy': 0.4287365561752448, 'lumpiness': 2.0317879601323604e-05, 'stability': 0.03180185085604344, 'flat_spots': 2, 'hurst': -0.08023291030513345, 'std1st_der': 0.043740012626144645, 'crossing_points': 7, 'binarize_mean': 0.4444444444444444, 'unitroot_kpss': 0.1284750818014943, 'heterogeneity': 126.06450625819339, 'histogram_mode': 0.2504823151125402, 'linearity': 0.8536381656031872, 'trend_strength': 0.9383301875692747, 'seasonality_strength': 0.3299338017939567, 'spikiness': 7.462446542148283e-10, 'peak': 6, 'trough': 3, 'level_shift_idx': 118, 'level_shift_size': 0.025080385852090048, 'y_acf1': 0.9480473407524915, 'y_acf5': 3.392072131604335, 'diff1y_acf1': 0.3028552581521692, 'diff1y_acf5': 0.25945910659994703, 'diff2y_acf1': -0.19100586757092758, 'diff2y_acf5': 0.13420736423784568, 'y_pacf5': 1.003288249401527, 'diff1y_pacf5': 0.21941234780081384, 'diff2y_pacf5': 0.26101034286994845, 'seas_acf1': 0.6629043863684491, 'seas_pacf1': 0.156169552555893, 'firstmin_ac': 8, 'firstzero_ac': 52, 'holt_alpha': 0.9999999850988388, 'holt_beta': nan, 'hw_alpha': 0.9999999850988388, 'hw_beta': nan, 'hw_gamma': nan}.\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "WARNING:fbprophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "INFO:fbprophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "WARNING:fbprophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "WARNING:fbprophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning:\n",
      "\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "WARNING:fbprophet.models:Optimization terminated abnormally. Falling back to Newton.\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/base/tsa_model.py:527: ValueWarning:\n",
      "\n",
      "No frequency information was provided, so inferred frequency MS will be used.\n",
      "\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning:\n",
      "\n",
      "Inverting hessian failed, no bse or cov_params available\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from kats.consts import TimeSeriesData\n",
    "from kats.models.metalearner.get_metadata import GetMetaData\n",
    "\n",
    "#load data and transform it into TimeSeriesData\n",
    "data = pd.read_csv(\"../kats/data/air_passengers.csv\")\n",
    "data.columns = [\"time\", \"y\"]\n",
    "TSdata = TimeSeriesData(data)\n",
    "\n",
    "# create an object MD of class GetMetaData\n",
    "MD = GetMetaData(data=TSdata, error_method='mape')\n",
    "\n",
    "# get meta data, as well as search method and type of error metric\n",
    "my_meta_data = MD.get_meta_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hpt_res', 'features', 'best_model', 'search_method', 'error_method'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the components of metadata\n",
    "my_meta_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'length': 144,\n",
       " 'mean': 0.45064085387638453,\n",
       " 'var': 0.03694123647244219,\n",
       " 'entropy': 0.4287365561752448,\n",
       " 'lumpiness': 2.0317879601323604e-05,\n",
       " 'stability': 0.03180185085604344,\n",
       " 'flat_spots': 2,\n",
       " 'hurst': -0.08023291030513345,\n",
       " 'std1st_der': 0.043740012626144645,\n",
       " 'crossing_points': 7,\n",
       " 'binarize_mean': 0.4444444444444444,\n",
       " 'unitroot_kpss': 0.1284750818014943,\n",
       " 'heterogeneity': 126.06450625819339,\n",
       " 'histogram_mode': 0.2504823151125402,\n",
       " 'linearity': 0.8536381656031872,\n",
       " 'trend_strength': 0.9383301875692747,\n",
       " 'seasonality_strength': 0.3299338017939567,\n",
       " 'spikiness': 7.462446542148283e-10,\n",
       " 'peak': 6,\n",
       " 'trough': 3,\n",
       " 'level_shift_idx': 118,\n",
       " 'level_shift_size': 0.025080385852090048,\n",
       " 'y_acf1': 0.9480473407524915,\n",
       " 'y_acf5': 3.392072131604335,\n",
       " 'diff1y_acf1': 0.3028552581521692,\n",
       " 'diff1y_acf5': 0.25945910659994703,\n",
       " 'diff2y_acf1': -0.19100586757092758,\n",
       " 'diff2y_acf5': 0.13420736423784568,\n",
       " 'y_pacf5': 1.003288249401527,\n",
       " 'diff1y_pacf5': 0.21941234780081384,\n",
       " 'diff2y_pacf5': 0.26101034286994845,\n",
       " 'seas_acf1': 0.6629043863684491,\n",
       " 'seas_pacf1': 0.156169552555893,\n",
       " 'firstmin_ac': 8,\n",
       " 'firstzero_ac': 52,\n",
       " 'holt_alpha': 0.9999999850988388,\n",
       " 'holt_beta': nan,\n",
       " 'hw_alpha': 0.9999999850988388,\n",
       " 'hw_beta': nan,\n",
       " 'hw_gamma': nan}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_meta_data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSfeature=pd.DataFrame(my_meta_data['features'], index=['value'])\n",
    "#TSfeature.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract search method and error metric\n",
    "print('Search method used is: ', my_meta_data['search_method'])\n",
    "\n",
    "print('Error metric used is: ', my_meta_data['error_method'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we pre-collected meta-data from m3 monthly data to demonstrate how to build and use meta-learning models. Notice that we are using a very small meta-data dataset (i.e., 78 records) and hence the performance of meta-learning models may not be ideal. In real applications, please considering using a relatively large meta-data dataset to ensure good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def change_format(tmp):\n",
    "    tmp['hpt_res']=eval(tmp['hpt_res'])\n",
    "    tmp['hpt_res']['sarima'][0]['seasonal_order'] = eval(tmp['hpt_res']['sarima'][0]['seasonal_order'])\n",
    "    tmp['features']=eval(tmp['features'])\n",
    "    return tmp\n",
    "\n",
    "\n",
    "meta_data_df = pd.read_csv(\"../kats/data/m3_meta_data.csv\")\n",
    "meta_data = [change_format(meta_data_df.iloc[i].to_dict()) for i in range(len(meta_data_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Meta-learning Predictability (Optional)** \n",
    "\n",
    "Before using meta-learning models for model and hyper-parameters forecasting, we would like to know whether a target time series can be easily fitted by a simple model or should be taken care of by extra human efforts. If a time series is taken as unpredictable, then the results given by our meta-learning framework may not be satisfying. Whether a time series is predictable or not is defined by user via specifying the \"threshold\" parameter for a target error metric (i.e., the model will take the time series with error metric>=threshold as unpredicable). This step is optional.\n",
    "\n",
    "Parameters for MetaLearnPredictability() class:\n",
    "* **metadata**: Optional; A list of dictionaries representing the meta-data of time series (e.g., the meta-data generated by GetMetaData object).Each dictionary d must contain at least 3 components: 'hpt_res', 'features' and 'best_model'. d['hpt_res'] represents the best hyper-parameters for each candidate model and the corresponding errors;\n",
    "d['features'] are time series features, and d['best_model'] is a string representing the best candidate model of the corresponding time series data. metadata should not be None unless load_model is True. Default is None\n",
    "\n",
    "* **threshold**: Optional; A float representing the threshold for the forecasting error. A time series whose forecasting error of the best forecasting model is higher than the threshold is considered as unpredictable. Default is 0.2.\n",
    "\n",
    "* **load_model**: Optional; A boolean to specify whether or not to load a trained model. Default is None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load class \n",
    "from kats.models.metalearner.metalearner_predictability import MetaLearnPredictability\n",
    "\n",
    "#take the time series with MAPE>=0.2 as unpreditable time series and initial the object\n",
    "mlp=MetaLearnPredictability(meta_data, threshold=0.2)\n",
    "\n",
    "#train a meta-learning predictability model and display the evaluation metrics on the test_set\n",
    "test_metrics=mlp.train()\n",
    "print(\"evaluation on test_set: \", test_metrics)\n",
    "\n",
    "#test whether TSdata is predictable or not\n",
    "val=mlp.pred(TSdata)\n",
    "val=(True if val==1 else False)\n",
    "print(\"TSdata is predictable: {}\".format(val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. **Meta-learn Model Selection**\n",
    "\n",
    "The MetaLearnModelSelect object helps to predict which predictive model is the most suitable one for the target time series.\n",
    "\n",
    "Parameters for MetaLearnModelSelect():\n",
    "* **metadata**: Optional; A list of dictionaries representing the meta-data of time series (e.g., the meta-data generated by GetMetaData object). Each dictionary d must contain at least 3 components: 'hpt_res', 'features' and 'best_model'. d['hpt_res'] represents the best hyper-parameters for each candidate model and the corresponding errors; d['features'] are time series features, and d['best_model'] is a string representing the best candidate model of the corresponding time series data. metadata should not be None unless load_model is True. Default is None\n",
    "* **load_model**: Optional; A boolean to specify whether or not to load a trained model. Default is False.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load MetaLearnModelSelect\n",
    "from kats.models.metalearner.metalearner_modelselect import MetaLearnModelSelect\n",
    "\n",
    "#create an object mlms of class MetaLearnModelSelect\n",
    "mlms = MetaLearnModelSelect(meta_data)\n",
    "\n",
    "#get class info\n",
    "counter=mlms.count_category()\n",
    "print(\"number of time series for each model: \", counter)\n",
    "\n",
    "#preprocessing meta-data: \n",
    "#not down-sample the meta-data to create the balanced data and standarized time series features to zero mean and unit standard deviation\n",
    "mlms.preprocess(downsample=False, scale=True)\n",
    "\n",
    "#generate features comparison plot\n",
    "mlms.plot_feature_comparison(10, 35)\n",
    "\n",
    "# generate heat map of correlation matrix of time series feature matrix\n",
    "mlms.plot_corr_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meta-learning modelselect model is basically a multi-class classifier, and we currently support random foreset (default), GBDT, SVM, KNN, and naive Bayes. We also display the evaluation of the classifier in term of error metrics (i.e., MAPE for our example) on both the training set and test set, compared with the averaged error metric of using one model for all time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a modelselect model using random forest algorithm   \n",
    "results=mlms.train()\n",
    "\n",
    "#display evaluation metrics of MetaLearnModelSelect\n",
    "summary=pd.DataFrame([results['fit_error'], results['pred_error']])\n",
    "summary['type']=['fit_error', 'pred_error']\n",
    "summary['error_metric']='MAPE'\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict forecasting model for a new time series data\n",
    "pred_model = mlms.pred(TSdata)\n",
    "print('Predicted forecasting model of this given time series data is: ', pred_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save trained model and load a pre-trained model\n",
    "mlms.save_model(\"mlms.pkl\")\n",
    "\n",
    "#initiate a new object and load the trained model\n",
    "mlms2 = MetaLearnModelSelect(load_model=True)\n",
    "mlms2.load_model(\"mlms.pkl\")\n",
    "\n",
    "#predict forecasting model with new MetaLearnModelSelect object\n",
    "pred_model = mlms2.pred(TSdata)\n",
    "print('Predicted forecasting model of this given time series data is: ', pred_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. **Meta-learning Hyper-parameter Selection**\n",
    "\n",
    "The MetaLearnHPT model generates the suitable hyper-parameters for a target time series given a designated model. We train a multi-task neural network using the optimal hyper-parameters from the meta-data and use it to predict the hyper-parameters.\n",
    "\n",
    "Some importand parameters for MetaLearnHPT():\n",
    "* **data_x**: Optional; A pd.DataFrame of time series features. data_x should not be None unless load_model is True. Default is None.\n",
    "* **data_y**: Optional; A pd.DataFrame of the corresponding best hyper-parameters. data_y should not be None unless load_model is True. Default is None.\n",
    "* **categorical_idx**: Optional; A list of strings of the names of the categorical hyper-parameters. Default is None.\n",
    "    If there is no categorical variable, then set categorical_idx as empty list.\n",
    "* **numerical_idx**: Optional; A list of strings of the names of the numerical hyper-parameters. Default is None.\n",
    "    If there is no numerical variables, then set numerical_idx as an empty list.\n",
    "* **default_model**: Optional; A string of the name of the forecast model whose default settings will be used. Can be 'arima', 'sarima', 'theta', 'prophet', 'holtwinters', 'stlf' or None. Default is None.\n",
    "    If None, then a customized model will be initiated.\n",
    "* **load_model**: Optional; A boolean to specify whether or not to load a trained model. Default is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform meta-data into pd.DataFrame\n",
    "mlhpt_table={}\n",
    "for m in ['arima', 'sarima', 'stlf', 'theta', 'prophet', 'holtwinters']:\n",
    "    mlhpt_table[m]={'x':[], 'y':[]}\n",
    "    for elm in range(len(meta_data)):\n",
    "        mlhpt_table[m]['x'].append(meta_data[elm]['features'])\n",
    "        mlhpt_table[m]['y'].append(meta_data[elm]['hpt_res'][m][0])\n",
    "\n",
    "for tab in mlhpt_table:\n",
    "    mlhpt_table[tab]['x']=pd.DataFrame(mlhpt_table[tab]['x'])\n",
    "    mlhpt_table[tab]['y']=pd.DataFrame(mlhpt_table[tab]['y'])\n",
    "    \n",
    "#load MetaLearnHPT\n",
    "from kats.models.metalearner.metalearner_hpt import MetaLearnHPT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 MetaLearnHPT with default NNs\n",
    "\n",
    "For the users who want to avoid specifying the types of hyper-parameters and the neural network structures, we provide user-friendly default neural network structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object using our default neural network (take Holt-Winter's model as an example)\n",
    "tab='holtwinters'\n",
    "mlhpt_holtwinters = MetaLearnHPT(\n",
    "    data_x=mlhpt_table[tab]['x'],\n",
    "    data_y=mlhpt_table[tab]['y'],\n",
    "    default_model=tab\n",
    ")\n",
    "\n",
    "#build a multi-task neural network using our default NN structure\n",
    "mlhpt_holtwinters.build_network()\n",
    "\n",
    "#train the multi-task NN\n",
    "mlhpt_holtwinters.train(lr=0.001, batch_size=20)\n",
    "\n",
    "#plot the training curves\n",
    "mlhpt_holtwinters.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict hyper-parameters using TimeSeriesData\n",
    "pred=mlhpt_holtwinters.pred(TSdata)\n",
    "print(\"predict hyper-parameters: \", pred['parameters'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "mlhpt_holtwinters.save_model(\"mlhpt_hw.pkl\")\n",
    "\n",
    "#initiate a new object to load the trained model\n",
    "mlhpt2=MetaLearnHPT(load_model=True)\n",
    "mlhpt2.load_model(\"mlhpt_hw.pkl\")\n",
    "\n",
    "#get prediction using the new object\n",
    "pred=mlhpt2.pred(TSdata)\n",
    "print(\"predict hyper-parameters: \", pred['parameters'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 MetaLearnHPT with customized NNs\n",
    "\n",
    "We also give users the flexibility to specify their own NNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object with customized structures (take Holt-Winter's model as an example).\n",
    "mlhpt_holtwinters=MetaLearnHPT(\n",
    "    data_x=pd.DataFrame(mlhpt_table[tab]['x']),\n",
    "    data_y=pd.DataFrame(mlhpt_table[tab]['y']),\t\n",
    "    #specify the names of cateogrical label\n",
    "    categorical_idx = [\n",
    "                        \"trend\",\n",
    "                        \"damped\",\n",
    "                        \"seasonal\",\n",
    "                    ],\n",
    "    #specify the names of continuous label\n",
    "    numerical_idx = [\"seasonal_periods\"]\n",
    "    \n",
    ")\n",
    "\n",
    "#build the customized NN\n",
    "mlhpt_holtwinters.build_network(\n",
    "    #One shared one-layer NN with 50 neurons.\n",
    "    n_hidden_shared=[50],\n",
    "    #Each classification task has its own task-specific NN. In this example, \"trend\" and \"dampled\" both have a two-layer NN respectively\n",
    "    #and \"seasonal\" has a one-layer NN.\n",
    "    n_hidden_cat_combo=[[20, 10], [20, 10], [20]], \n",
    "    #One task-specific one-layer NN with 30 neurons for regression task.\n",
    "    n_hidden_num=[30]\n",
    ")\n",
    "\n",
    "#train the customized NN\n",
    "mlhpt_holtwinters.train(    \n",
    "    #loss_scale is used to balance 2 types of losses: cross-entropy for classification tasks and MSE for regression tasks\n",
    "    loss_scale=30,\n",
    "    #learning rate\n",
    "    lr=0.005,\n",
    "    n_epochs=2000,\n",
    "    batch_size=16,\n",
    "    #supports ADAM and SGD\n",
    "    method='SGD',\n",
    "    #momentum in SGD.\n",
    "    momentum=0,\n",
    "    #early stop option.\n",
    "    n_epochs_stop=50,)\n",
    "\n",
    "#plot the training curves\n",
    "mlhpt_holtwinters.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "mlhpt_holtwinters.pred(TSdata)\n",
    "print(\"predict hyper-parameters: \", pred['parameters'].iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "5b6e8fba36db23bc4d54e0302cd75fdd75c29d9edcbab68d6cfc74e7e4b30305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
