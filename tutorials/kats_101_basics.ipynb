{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kats 101 - Basics\n",
    "\n",
    "Kats (**K**its to **A**nalyze **T**ime **S**eries) is a light-weight, easy-to-use, extenable, and generalizable framework to perform time series analysis in Python.  Time series analysis is an essential component of data science and engineering work.  Kats aims to provide a one-stop shop for techniques for univariate and multivariate time series including:\n",
    "\n",
    "1. Forecasting  \n",
    "2. Anomaly and Change Point Detection  \n",
    "3. Feature Extraction \n",
    "\n",
    "\n",
    "and after introducing the basic Kats data structure, this Kats 101 notebook provides a basic introduction to each of these time series techniques in Kats.  The complete table of contents for Kats 101 is as follows: \n",
    "\n",
    "1. Kats Basics          \n",
    "    1.1 Initiate `TimeSeriesData` Object         \n",
    "    1.2 `TimeSeriesData` built-in operations         \n",
    "2. Forecasting with Kats         \n",
    "    2.1 An example with Prophet model         \n",
    "    2.2 An example with Theta model         \n",
    "3. Detection with Kats         \n",
    "    3.1 What are the algorithms?         \n",
    "    3.2 An example with outlier detection method         \n",
    "    3.3 An example with CUSUM algorithm         \n",
    "4. Feature extraction with Kats         \n",
    "5. Summary         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We provide two types of tutorial notebooks\n",
    "- **Kats 101**, basic data structure and functionalities in Kats (this tutorial)  \n",
    "- **Kats 20x**, advanced topics, including advanced forecasting techniques, advanced detection algorithms, `TsFeatures`, meta-learning, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kats Basics\n",
    "`TimeSeriesData` is the basic data structure in Kats to represented univariate and multivariate time series.  There are two ways to initiate it, henceforth referred to as \"Method 1\" and \"Method 2\":\n",
    "\n",
    "1) `TimeSeriesData(df)`, where `df` is a `pd.DataFrame` object with a \"time\" column and any number of value columns.\n",
    "\n",
    "2) `TimeSeriesData(time, value)`, where `time` is either a `pd.Series` or `pd.DatetimeIndex` object and `value` is either a `pd.Series` (for univariate) or a `pd.DataFrame` (for multivariate)\n",
    "\n",
    "## 1.1 Initiate `TimeSeriesData` object\n",
    "We will use the `air_passenger` and `multi_ts` datasets to demonstrate how to create a `TimeSeriesData` object for univariate and multivariate time series, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# For Google Colab:\n",
    "!pip install kats\n",
    "!wget https://raw.githubusercontent.com/facebookresearch/Kats/main/kats/data/air_passengers.csv\n",
    "!wget https://raw.githubusercontent.com/facebookresearch/Kats/main/kats/data/multi_ts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from kats.consts import TimeSeriesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # If running on Jupyter\n",
    "    air_passengers_df = pd.read_csv(\"../kats/data/air_passengers.csv\")\n",
    "except FileNotFoundError: # If running on colab\n",
    "    air_passengers_df = pd.read_csv(\"air_passengers.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Note: If the column holding the time values is not called \"time\", you will want to specify \n",
    "the name of this column using the time_col_name parameter in the TimeSeriesData constructor.\n",
    "\"\"\"\n",
    "air_passengers_df.columns = [\"time\", \"value\"]\n",
    "air_passengers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # If running on Jupyter\n",
    "    multi_ts_df = pd.read_csv(\"../kats/data/multi_ts.csv\", index_col=0)\n",
    "except FileNotFoundError: # If running on colab\n",
    "    multi_ts_df = pd.read_csv(\"multi_ts.csv\", index_col=0)\n",
    "multi_ts_df.columns = [\"time\", \"v1\", \"v2\"]\n",
    "multi_ts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct `TimeSeriesData` objects for each time series using Method 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts = TimeSeriesData(air_passengers_df)\n",
    "multi_ts = TimeSeriesData(multi_ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the type of the data is a \"TimeSeriesData\" object for both cases\n",
    "print(type(air_passengers_ts))\n",
    "print(type(multi_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the air_passengers TimeSeriesData, check that both time and value are pd.Series\n",
    "print(type(air_passengers_ts.time))\n",
    "print(type(air_passengers_ts.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the multi_ts TimeSeriesData, time is a pd.Series and value is a pd.DataFrame\n",
    "print(type(multi_ts.time))\n",
    "print(type(multi_ts.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we show how to construct the same `TimeSeriesData` objects as before using Method 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts_from_series = TimeSeriesData(time=air_passengers_df.time, value=air_passengers_df.value)\n",
    "multi_ts_from_series = TimeSeriesData(time=multi_ts_df.time, value=multi_ts_df[['v1', 'v2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TimeSeriesData` can accomodate time expressed as a variety of different types, including \n",
    "- standard `datetime`, \n",
    "- `pandas.Timestamp`,\n",
    "- a `str` (if in a non-standard format or if efficiency is important, use the optional `date_format` argument),\n",
    "- `int` (i.e. unix time).\n",
    "\n",
    "Here is an example of how to construct a `TimeSeriesData` object when time is provided in unix time format.\n",
    "\n",
    "\n",
    "Here's an example where the time is auto-interpreted from a unix time format. Using this format just requires a couple optional parameters in the `TimeSeriesData` constructor:\n",
    "- `use_unix_time = True`\n",
    "- `unix_time_units=\"s\"` (the default is `\"ns\"`, indicating nanoseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert time from air_passengers data to unix time\n",
    "air_passengers_ts_unixtime = air_passengers_df.time.apply(\n",
    "    lambda x: datetime.timestamp(parser.parse(x))\n",
    ")\n",
    "\n",
    "air_passengers_ts_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TimeSeriesData object with the extra arguments to accomodate unix time \n",
    "ts_from_unixtime = TimeSeriesData(\n",
    "        time=air_passengers_ts_unixtime, \n",
    "        value=air_passengers_df.value, \n",
    "        use_unix_time=True, \n",
    "        unix_time_units=\"s\"\n",
    ")\n",
    "\n",
    "ts_from_unixtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 `TimeSeriesData` built-in operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TimeSeriesData` object supports many of the same operations of the standard `pandas.DataFrame`, including:\n",
    "- Slicing\n",
    "- Math Operations\n",
    "- Extend \n",
    "- Plotting\n",
    "- Utility Functions (`to_dataframe`, `to_array`, `is_empty`, `is_univariate`)\n",
    "\n",
    "We give examples of each as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts[1:5] + air_passengers_ts[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equality and Inequality are also supported:\n",
    "\n",
    "air_passengers_ts == air_passengers_ts_from_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_ts == multi_ts_from_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length\n",
    "\n",
    "len(air_passengers_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two slices\n",
    "ts_1 = air_passengers_ts[0:3]\n",
    "ts_2 = air_passengers_ts[3:7]\n",
    "\n",
    "ts_1.extend(ts_2)\n",
    "ts_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Must pass the name of the value columns to plot\n",
    "air_passengers_ts.plot(cols=['value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot multiple time series from multi_ts by passing in the name of each value column we want to plot\n",
    "multi_ts.plot(cols=['v1','v2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "Here we provide examples of a few useful Kats utility functions for `TimeSeriesData`.  They can be helpful for working with external libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to `numpy.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts.to_array()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check basic characteristics of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts.is_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts.is_univariate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_ts.is_univariate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Forecasting with Kats\n",
    "\n",
    "We currently support the following 10 base forecasting models: \n",
    "\n",
    "1. Linear  \n",
    "2. Quadratic   \n",
    "3. ARIMA   \n",
    "4. SARIMA   \n",
    "5. Holt-Winters   \n",
    "6. Prophet   \n",
    "7. AR-Net   \n",
    "8. LSTM   \n",
    "9. Theta   \n",
    "10. VAR   \n",
    "\n",
    "\n",
    "Each models follows the `sklearn` model API pattern:  we create an instance of the model class and then call its `fit` and `predict` methods.  In this section, we provide examples for the Prophet and Theta models.  A more in-depth introduction to forecasting in Kats is provided in the Kats 201 tutorial.\n",
    "\n",
    "\n",
    "\n",
    "## 2.1 An example with Prophet model\n",
    "\n",
    "We will demonstrate how to use Prophet model to forecast with the `air_passengers` data set. Note: this example requires that fbprophet be installed (for example, `pip install kats[prophet]` or `pip install kats[all]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the param and model classes for Prophet model\n",
    "from kats.models.prophet import ProphetModel, ProphetParams\n",
    "\n",
    "# create a model param instance\n",
    "params = ProphetParams(seasonality_mode='multiplicative') # additive mode gives worse results\n",
    "\n",
    "# create a prophet model instance\n",
    "m = ProphetModel(air_passengers_ts, params)\n",
    "\n",
    "# fit model simply by calling m.fit()\n",
    "m.fit()\n",
    "\n",
    "# make prediction for next 30 month\n",
    "fcst = m.predict(steps=30, freq=\"MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the predict method returns a dataframe as follows\n",
    "fcst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results with uncertainty intervals\n",
    "m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 An example with Theta model\n",
    "\n",
    "\n",
    "We will now use the Theta model to forecast with the `air_passengers` data set.  \n",
    "\n",
    "The Theta Method (Assimakopoulos and Nikolopoulos, 2000) is a univariate forecasting method that fits two Theta lines: 1) a linear interpolation (called the `Theta=0`) and 2) a second-order difference (called the `Theta=2` line), and then combines them to build a forecast.  Prior to running this forecast, we test the time series for seasonality, deseaonalize if seasonality is detected, and then reseasonalize the calculated forecasts.  \n",
    "\n",
    "Hyndman and Billah (2003) showed that the Theta Method is equivalent to simple exponential smoothing with drift.  In Kats we use this underlying model to calculate prediction intervals for `ThetaModel`.\n",
    "\n",
    "Our implementation of `ThetaModel` in Kats is similar to the [thetaf function in R](https://pkg.robjhyndman.com/forecast/reference/thetaf.html).  Because each of our time series models follow the `sklearn` model API pattern, the code using `ThetaModel` is quite similar to the example above using \n",
    "`ProphetModel`: we initialize the model with its parameters and then call the `fit` and `predict` methods.  We can then use the `plot` method to visualize our forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import param and model from `kats.models.theta`\n",
    "from kats.models.theta import ThetaModel, ThetaParams\n",
    "\n",
    "# create ThetaParam with specifying seasonality param value\n",
    "params = ThetaParams(m=12)\n",
    "\n",
    "# create ThetaModel with given data and parameter class\n",
    "m = ThetaModel(data=air_passengers_ts, params=params)\n",
    "\n",
    "# call fit method to fit model\n",
    "m.fit()\n",
    "\n",
    "# call predict method to predict the next 30 steps\n",
    "res = m.predict(steps=30, alpha=0.2)\n",
    "\n",
    "# visualize the results\n",
    "m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Detection with Kats\n",
    "\n",
    "Kats provides a set of models and algorithms to detect outliers, change points, and trend changes in time series data.\n",
    "\n",
    "\n",
    "## 3.1 What are the algorithms?\n",
    "\n",
    "To detect a specific pattern, we provided different algorithms, which is summarized as follows.\n",
    "- **Outlier Detection**. This usually refers to a abnormal spike in a time series data, which can be detected with `OutlierDetector`\n",
    "- **Change Point Detection**. This refers to a sudden change that the time series have different statistical properties before and after the change. We provided three major algorithms to detect such patterns:\n",
    "    - CUSUM Detection\n",
    "    - Bayesian Online Change Point Detection (BOCPD)\n",
    "    - Stat Sig Detection\n",
    "- **Trend Change Detection**. This refers to a slow trend change on the time series data, which can be detected with Mann-Kendall detection algorithm, `MKDetector`\n",
    "\n",
    "In this tutorial, we will demonstrate the usage of two detectors: `OutlierDetector` and `CUSUM`.  A more in-depth introduction to detection in Kats is provided in the Kats 202 tutorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 An example with outlier detection method\n",
    "\n",
    "We provide the `OutlierDetector` module to detect outliers in time series.  Since outliers can cause so many problems in downstream processing, it is important to be able to detect them.  `OutlierDetector` also provides functionality to handle or remove outliers once they are found.\n",
    "\n",
    "Our outlier detection algorithm works as follows:\n",
    "\n",
    "- We do a [seasonal decomposition](https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html) of the input time series with additive or multiplicative decomposition as specified (default is additive)\n",
    "- We generate a residual time series by either removing only trend or both trend and seasonality if the seasonality is strong.\n",
    "- We detect points in the residual which are outside 3 times the inter quartile range.  This multiplier can be tuned using the `iqr_mult` parameter in `OutlierDetector`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example below copies the `air_passengers` data set and manually inserts outliers into it. We then use `OutlierDetector` to find them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep copy the air_passenger_df \n",
    "air_passengers_outlier_df = air_passengers_df.copy(deep=True)\n",
    "\n",
    "# manually add outlier on the date of '1950-12-01'\n",
    "air_passengers_outlier_df.loc[air_passengers_outlier_df.time == '1950-12-01','value']*=5\n",
    "# manually add outlier on the date of '1959-12-01'\n",
    "air_passengers_outlier_df.loc[air_passengers_outlier_df.time == '1959-12-01', 'value']*=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the raw data\n",
    "air_passengers_outlier_df.plot(x='time', y='value', figsize=(15,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the outlier data into `TimeSeriesData` Object\n",
    "air_passengers_outlier_ts = TimeSeriesData(air_passengers_outlier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kats.detectors.outlier import OutlierDetector\n",
    "\n",
    "ts_outlierDetection = OutlierDetector(air_passengers_outlier_ts, 'additive') # call OutlierDetector\n",
    "ts_outlierDetection.detector() # apply OutlierDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at the outliers that the algorithm found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_outlierDetection.outliers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After detecting the outlier, we can now easily removal them from the data. Here we will explore two options: \n",
    "- **No Interpolation**: outlier data points will be replaced with **NaN** values\n",
    "- **With Interpolation**: outlier data points will be replaced with **linear interploation** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_passengers_ts_outliers_removed = ts_outlierDetection.remover(interpolate = False) # No interpolation\n",
    "air_passengers_ts_outliers_interpolated = ts_outlierDetection.remover(interpolate = True) # With interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize the difference between these two approaches to removing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8), nrows=1, ncols=2)\n",
    "\n",
    "air_passengers_ts_outliers_removed.to_dataframe().plot(x = 'time',y = 'y_0', ax= ax[0])\n",
    "ax[0].set_title(\"Outliers Removed : No interpolation\")\n",
    "air_passengers_ts_outliers_interpolated.to_dataframe().plot(x = 'time',y = 'y_0', ax= ax[1])\n",
    "ax[1].set_title(\"Outliers Removed : With interpolation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 An example with CUSUM algorithm\n",
    "\n",
    "Cusum is a method to detect an up/down shift of means in a time series. Our implementation has two main steps:\n",
    "\n",
    "1.  **Locate the change point:** This is an iterative process where we initialize a change point (in the middle of the time series) and CUSUM time series based on this change point.  The next changepoint is the location where the previous CUSUM time series is maximized (or minimized).  This iteration continues until either 1) a stable changepoint is found or 2) we exceed the limit number of iterations.\n",
    "\n",
    "2.  **Test the change point for statistical significance:** Conduct log likelihood ratio test to test if the mean of the time series changes at the changepoint calculated in Step 1.  The null hypothesis is that there is no change in mean.\n",
    "\n",
    "By default, we report a detected changepoint if and only if we reject the null hypothesis in Step 2.  \n",
    "\n",
    "Here are a few additional points worth mentioning:\n",
    "- We assume there is at most one increase change point and at most one decrease change point.  You can use the `change_directions` argument in the detector to specify whether you are looking an increase, a decrease, or both (default is both).\n",
    "- We use Gaussian distribution as the underlying model to calculate the CUSUM time series value and conduct the hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from kats.consts import TimeSeriesData, TimeSeriesIterator\n",
    "from kats.detectors.cusum_detection import CUSUMDetector\n",
    "\n",
    "# synthesize data with simulation\n",
    "np.random.seed(10)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'time': pd.date_range('2019-01-01', '2019-03-01'),\n",
    "        'increase':np.concatenate([np.random.normal(1,0.2,30), np.random.normal(2,0.2,30)]),\n",
    "        'decrease':np.concatenate([np.random.normal(1,0.3,50), np.random.normal(0.5,0.3,10)]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is straightforward to use `CUSUMDetector` to detect an increase or a decrease when there is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect increase\n",
    "timeseries = TimeSeriesData(\n",
    "    df.loc[:,['time','increase']]\n",
    ")\n",
    "detector = CUSUMDetector(timeseries)\n",
    "\n",
    "# run detector\n",
    "change_points = detector.detector(change_directions=[\"increase\"])\n",
    "\n",
    "# plot the results\n",
    "detector.plot(change_points)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect decrease\n",
    "timeseries = TimeSeriesData(\n",
    "    df.loc[:,['time','decrease']]\n",
    ")\n",
    "detector = CUSUMDetector(timeseries)\n",
    "\n",
    "# run detector\n",
    "change_points = detector.detector(change_directions=[\"decrease\"])\n",
    "\n",
    "# plot the results\n",
    "detector.plot(change_points)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to detect a decrease in a series where there is only an increase, no change point will be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect increase\n",
    "timeseries = TimeSeriesData(\n",
    "    df.loc[:,['time','increase']]\n",
    ")\n",
    "detector = CUSUMDetector(timeseries)\n",
    "\n",
    "# run detector\n",
    "change_points = detector.detector(change_directions=[\"decrease\"])\n",
    "\n",
    "# plot the results\n",
    "detector.plot(change_points)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not specify which change directions we are looking for, `CUSUMDetector` will look for both increases and decreases.  In the case below where there is only an increase, it will detect that increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect increase\n",
    "timeseries = TimeSeriesData(\n",
    "    df.loc[:,['time','increase']]\n",
    ")\n",
    "detector = CUSUMDetector(timeseries)\n",
    "\n",
    "# run detector\n",
    "change_points = detector.detector()\n",
    "\n",
    "# plot the results\n",
    "detector.plot(change_points)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Extraction with Kats\n",
    "\n",
    "We provide the `TsFeatures` module to calculate a set of meaningful features for a time series, including:\n",
    "- STL (Seasonal and Trend decomposition using Loess) Features\n",
    "    - Strength of Seasonality\n",
    "    - Strength of Trend\n",
    "    - Spikiness\n",
    "    - Linearity\n",
    "- Amount of Level Shift\n",
    "- Presence of Flat Segments\n",
    "- ACF and PACF Features\n",
    "- Hurst Exponent\n",
    "- ARCH Statistic\n",
    "\n",
    "Given a collection of time series, these features can be used to identify specific series that are similar or outlying.  Our `TsFeatures` module is similar to the one that is [freely available in R](https://pkg.robjhyndman.com/tsfeatures/index.html).\n",
    "\n",
    "These features also play a crucial role in many downstream projects, including \n",
    "1. “Meta-learning”, i.e., choosing the best forecasting model based on characteristics of the input time series \n",
    "2. Time series classification and clustering analysis\n",
    "3. Nowcasting algorithms for better short-term forecasting\n",
    "\n",
    "Now we will show you how to use `TsFeatures` get the features for the `air_passenger` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate feature extraction class\n",
    "from kats.tsfeatures.tsfeatures import TsFeatures\n",
    "tsFeatures = TsFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_air_passengers = TsFeatures().transform(air_passengers_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the dictionary of features as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_air_passengers\n",
    "features_air_passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Summary\n",
    "\n",
    "in this tutorial, we have shown the basic operations of **Kats** in time series application, including basic introductions to forecasting, detection, feature extraction in Kats.\n",
    "\n",
    "If you want to explore these topics in more detail, you can check out Kats 20x tutorials:\n",
    "\n",
    "- [Kats 201 Forecasting with Kats](kats_201_forecasting.ipynb)\n",
    "- [Kats 202 Detection with Kats](kats_202_detection.ipynb)\n",
    "- [Kats 203 Time Series Features](kats_203_tsfeatures.ipynb)\n",
    "- [Kats 204 Forecasting with Meta-Learning](kats_204_metalearning.ipynb)\n",
    "- [Kats 205 Forecasting with Global Model](kats_205_globalmodel.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "5b6e8fba36db23bc4d54e0302cd75fdd75c29d9edcbab68d6cfc74e7e4b30305"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
